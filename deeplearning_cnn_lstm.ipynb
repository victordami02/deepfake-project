{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c3ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f3a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df0141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, concatenate, Reshape\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9aa571",
   "metadata": {},
   "source": [
    "## Data preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3765fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "        if path.endswith(\".jpg\") or path.endswith(\".png\"):\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            img = cv2.resize(img, (224, 224))  # Resize images to a common size\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f82195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(data_folder):\n",
    "        label_folder = os.path.join(data_folder, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            label_images, label_labels = load_images_from_folder(label_folder, label)\n",
    "            images.extend(label_images)\n",
    "            labels.extend(label_labels)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f6e7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "train_folder = '/Users/mac/Documents/clonerepo/Deep-Fake-Model/dataset/train/'\n",
    "val_folder = '/Users/mac/Documents/clonerepo/Deep-Fake-Model/dataset/validation/'\n",
    "test_folder = '/Users/mac/Documents/clonerepo/Deep-Fake-Model/dataset/test/'\n",
    "\n",
    "train_images, train_labels = load_dataset(train_folder)\n",
    "val_images, val_labels = load_dataset(val_folder)\n",
    "test_images, test_labels = load_dataset(test_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ffedb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake'], dtype='<U4')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b51ff324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "train_images = train_images / 255.0\n",
    "val_images = val_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea380d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = to_categorical(label_encoder.fit_transform(train_labels))\n",
    "y_test_encoded = to_categorical(label_encoder.transform(test_labels))\n",
    "y_val_encoded = to_categorical(label_encoder.transform(val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d785eb",
   "metadata": {},
   "source": [
    "# Training with cnn and lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8795490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 111, 111, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               11075712  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11169089 (42.61 MB)\n",
      "Trainable params: 11169089 (42.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 14s 927ms/step - loss: 2.9406 - accuracy: 0.7649 - val_loss: 2.0537 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 12s 908ms/step - loss: 1.7197 - accuracy: 0.9554 - val_loss: 1.3934 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 12s 905ms/step - loss: 1.1403 - accuracy: 0.9777 - val_loss: 0.9874 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 12s 930ms/step - loss: 0.8349 - accuracy: 0.9728 - val_loss: 0.9183 - val_accuracy: 0.7838\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 12s 940ms/step - loss: 0.6302 - accuracy: 0.9827 - val_loss: 0.5810 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 12s 940ms/step - loss: 0.5827 - accuracy: 0.9802 - val_loss: 0.9182 - val_accuracy: 0.5946\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 21s 2s/step - loss: 0.5158 - accuracy: 0.9901 - val_loss: 0.9238 - val_accuracy: 0.5946\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.4193 - accuracy: 0.9901 - val_loss: 1.0057 - val_accuracy: 0.5946\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 13s 995ms/step - loss: 0.3806 - accuracy: 0.9926 - val_loss: 0.7141 - val_accuracy: 0.6351\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.3538 - accuracy: 0.9926 - val_loss: 0.7334 - val_accuracy: 0.6486\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Assuming img_size is (224, 224)\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Define the CNN model with regularization\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=img_size + (3,)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(layers.Dropout(0.5))  # Dropout layer added for regularization\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Assuming y_train and y_val are binary labels (0 or 1)\n",
    "history = model.fit(train_images, y_train_encoded[:, 1], epochs=10, validation_data=(val_images, y_val_encoded[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bc6bda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 473ms/step - loss: 3.0803 - accuracy: 0.5000\n",
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, y_test_encoded)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c19c44",
   "metadata": {},
   "source": [
    "# Prediction on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d47af441",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_Predict= '/Users/mac/Documents/clonerepo/Deep-Fake-Model/modi/dataset/test/'\n",
    "newdata_images_predict, new_data_labels_predict = load_dataset(new_data_Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05b5ce3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[115,  87,  82],\n",
       "         [112,  86,  77],\n",
       "         [111,  84,  73],\n",
       "         ...,\n",
       "         [199, 183, 154],\n",
       "         [197, 181, 151],\n",
       "         [195, 179, 146]],\n",
       "\n",
       "        [[113,  85,  81],\n",
       "         [113,  86,  78],\n",
       "         [113,  86,  74],\n",
       "         ...,\n",
       "         [201, 186, 157],\n",
       "         [200, 185, 154],\n",
       "         [198, 182, 150]],\n",
       "\n",
       "        [[109,  81,  77],\n",
       "         [111,  84,  75],\n",
       "         [113,  86,  74],\n",
       "         ...,\n",
       "         [201, 186, 156],\n",
       "         [203, 187, 159],\n",
       "         [202, 185, 157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[131,  96,  92],\n",
       "         [130,  91,  84],\n",
       "         [133,  90,  81],\n",
       "         ...,\n",
       "         [167, 115,  81],\n",
       "         [170, 117,  84],\n",
       "         [172, 119,  87]],\n",
       "\n",
       "        [[130,  95,  91],\n",
       "         [129,  90,  83],\n",
       "         [132,  89,  80],\n",
       "         ...,\n",
       "         [170, 118,  81],\n",
       "         [171, 119,  83],\n",
       "         [172, 119,  87]],\n",
       "\n",
       "        [[129,  94,  90],\n",
       "         [128,  89,  83],\n",
       "         [131,  88,  79],\n",
       "         ...,\n",
       "         [172, 120,  81],\n",
       "         [171, 119,  82],\n",
       "         [173, 120,  88]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [148, 117,  86],\n",
       "         [146, 115,  84],\n",
       "         [142, 111,  80]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [147, 116,  85],\n",
       "         [146, 115,  84],\n",
       "         [142, 111,  80]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [144, 113,  83],\n",
       "         [145, 114,  83],\n",
       "         [145, 114,  83]]],\n",
       "\n",
       "\n",
       "       [[[ 11,  10,   5],\n",
       "         [ 12,  11,   6],\n",
       "         [ 13,  12,   7],\n",
       "         ...,\n",
       "         [ 16,  11,   8],\n",
       "         [ 16,  11,   8],\n",
       "         [ 16,  11,   8]],\n",
       "\n",
       "        [[ 11,  10,   5],\n",
       "         [ 12,  11,   6],\n",
       "         [ 13,  12,   7],\n",
       "         ...,\n",
       "         [ 16,  11,   8],\n",
       "         [ 16,  11,   8],\n",
       "         [ 16,  11,   8]],\n",
       "\n",
       "        [[ 10,  10,   5],\n",
       "         [ 11,  10,   5],\n",
       "         [ 13,  11,   6],\n",
       "         ...,\n",
       "         [ 16,  11,   8],\n",
       "         [ 16,  11,   8],\n",
       "         [ 16,  11,   8]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 18,  18,  18],\n",
       "         [ 16,  17,  16],\n",
       "         [ 13,  13,  13],\n",
       "         ...,\n",
       "         [  5,   5,   5],\n",
       "         [  5,   5,   5],\n",
       "         [  5,   5,   5]],\n",
       "\n",
       "        [[ 18,  18,  18],\n",
       "         [ 17,  17,  17],\n",
       "         [ 14,  14,  14],\n",
       "         ...,\n",
       "         [  5,   5,   5],\n",
       "         [  5,   5,   5],\n",
       "         [  5,   5,   5]],\n",
       "\n",
       "        [[ 19,  19,  19],\n",
       "         [ 17,  17,  17],\n",
       "         [ 14,  14,  14],\n",
       "         ...,\n",
       "         [  5,   5,   5],\n",
       "         [  5,   5,   5],\n",
       "         [  5,   5,   5]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 14,  14,   7],\n",
       "         [ 16,  17,   5],\n",
       "         [ 21,  21,  16],\n",
       "         ...,\n",
       "         [ 14,  14,   9],\n",
       "         [ 16,  16,   9],\n",
       "         [ 16,  17,   9]],\n",
       "\n",
       "        [[ 14,  14,   7],\n",
       "         [ 16,  17,   6],\n",
       "         [ 20,  20,  15],\n",
       "         ...,\n",
       "         [ 15,  15,  10],\n",
       "         [ 16,  16,   9],\n",
       "         [ 16,  17,   9]],\n",
       "\n",
       "        [[ 12,  12,   5],\n",
       "         [ 15,  17,   5],\n",
       "         [ 20,  20,  15],\n",
       "         ...,\n",
       "         [ 18,  18,  13],\n",
       "         [ 16,  17,   8],\n",
       "         [ 16,  17,   7]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 58,  15,   0],\n",
       "         [ 64,  12,   0],\n",
       "         [ 59,  10,   0],\n",
       "         ...,\n",
       "         [ 41,  25,  19],\n",
       "         [ 26,   2,   0],\n",
       "         [ 29,   9,   7]],\n",
       "\n",
       "        [[ 57,  14,   0],\n",
       "         [ 65,  13,   0],\n",
       "         [ 60,  11,   0],\n",
       "         ...,\n",
       "         [ 33,  10,   7],\n",
       "         [ 19,   2,   0],\n",
       "         [ 60,  46,  41]],\n",
       "\n",
       "        [[ 58,  15,   0],\n",
       "         [ 67,  14,   2],\n",
       "         [ 60,  11,   0],\n",
       "         ...,\n",
       "         [ 29,   1,   0],\n",
       "         [ 20,   4,   1],\n",
       "         [ 54,  41,  36]]],\n",
       "\n",
       "\n",
       "       [[[ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         ...,\n",
       "         [ 61,  91, 131],\n",
       "         [ 61,  91, 131],\n",
       "         [ 61,  91, 131]],\n",
       "\n",
       "        [[ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         ...,\n",
       "         [ 60,  91, 130],\n",
       "         [ 61,  91, 131],\n",
       "         [ 61,  91, 129]],\n",
       "\n",
       "        [[ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         ...,\n",
       "         [ 60,  90, 130],\n",
       "         [ 61,  91, 131],\n",
       "         [ 61,  91, 129]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         ...,\n",
       "         [ 96,  87,  70],\n",
       "         [ 96,  87,  70],\n",
       "         [ 96,  87,  70]],\n",
       "\n",
       "        [[ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         ...,\n",
       "         [ 96,  87,  70],\n",
       "         [ 96,  87,  70],\n",
       "         [ 96,  87,  70]],\n",
       "\n",
       "        [[ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         ...,\n",
       "         [ 98,  87,  70],\n",
       "         [ 98,  87,  70],\n",
       "         [ 98,  87,  70]]],\n",
       "\n",
       "\n",
       "       [[[ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         ...,\n",
       "         [ 61,  91, 131],\n",
       "         [ 61,  91, 131],\n",
       "         [ 61,  91, 131]],\n",
       "\n",
       "        [[ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         ...,\n",
       "         [ 60,  90, 130],\n",
       "         [ 61,  91, 131],\n",
       "         [ 61,  91, 129]],\n",
       "\n",
       "        [[ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         [ 58,  89, 134],\n",
       "         ...,\n",
       "         [ 60,  90, 130],\n",
       "         [ 60,  90, 130],\n",
       "         [ 61,  91, 129]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         ...,\n",
       "         [ 96,  87,  70],\n",
       "         [ 96,  87,  70],\n",
       "         [ 96,  87,  70]],\n",
       "\n",
       "        [[ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         ...,\n",
       "         [ 96,  87,  70],\n",
       "         [ 96,  87,  70],\n",
       "         [ 96,  87,  70]],\n",
       "\n",
       "        [[ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         [ 95,  86,  69],\n",
       "         ...,\n",
       "         [ 98,  87,  70],\n",
       "         [ 98,  87,  70],\n",
       "         [ 98,  87,  70]]]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata_images_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9ad27cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 158ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata_imagespredicted = newdata_images_predict / 255.0\n",
    "# prediction\n",
    "new_predictions = model.predict(newdata_imagespredicted)\n",
    "# Example: Binary classification\n",
    "threshold = 0.5  # Adjust the threshold based on your needs\n",
    "\n",
    "new_binary_predictions = (new_predictions > threshold).astype(int)\n",
    "\n",
    "# Map binary labels to 'Real' or 'Fake'\n",
    "class_labels = ['Real', 'Fake']\n",
    "new_mapped_predictions = [class_labels[prediction] for prediction in new_binary_predictions.flatten()]\n",
    "new_mapped_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ee0a8",
   "metadata": {},
   "source": [
    "# Prediction on a single image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acd7fc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prediction: Real\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Assuming new_image_path is the file path of your new image\n",
    "new_image_path = \"/Users/mac/Documents/clonerepo/Deep-Fake-Model/modi/dataset/test/real/modi1.jpg\"\n",
    "\n",
    "# Load and preprocess the new image\n",
    "new_image = cv2.imread(new_image_path)\n",
    "new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
    "new_image = cv2.resize(new_image, (224, 224))  # Assuming your model takes input of size (224, 224)\n",
    "\n",
    "# Expand dimensions to match the input shape expected by the model\n",
    "new_image = np.expand_dims(new_image, axis=0)\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "new_image = new_image / 255.0\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_image)\n",
    "\n",
    "# The predictions will be in the range [0, 1] for binary classification\n",
    "# You can interpret the output based on your threshold (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "if predictions[0, 0] > threshold:\n",
    "    print(\"Prediction: Fake\")\n",
    "else:\n",
    "    print(\"Prediction: Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d7b99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"cnn_lstm.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795361a4",
   "metadata": {},
   "source": [
    "## Project Title: Deepfake Image Detection with CNN and LSTM Layers\n",
    "\n",
    "Overview:\n",
    "This project aims to develop a deep learning model for detecting deepfake images, focusing on binary classification of real and fake images. The model utilizes Convolutional Neural Networks (CNNs) for effective feature extraction from images and incorporates regularization techniques to improve generalization and prevent overfitting.\n",
    "\n",
    "Key Components:\n",
    "\n",
    "- Data Preparation:\n",
    "The dataset consists of images categorized as real and fake.\n",
    "Images are preprocessed by resizing, normalizing pixel values, and organizing them into training and validation sets.\n",
    "- Model Architecture:\n",
    "The core of the model comprises Conv2D layers for spatial feature extraction.\n",
    "MaxPooling layers are applied for downsampling spatial dimensions.\n",
    "A dense layer with Rectified Linear Unit (ReLU) activation functions captures complex features.\n",
    "Dropout layers are introduced for regularization, preventing overfitting.\n",
    "The output layer employs a sigmoid activation for binary classification.\n",
    "- Regularization Techniques:\n",
    "L2 regularization is applied to convolutional and dense layers to penalize large weights and encourage simpler models.\n",
    "Dropout layers randomly deactivate a fraction of neurons during training to enhance robustness.\n",
    "- Model Training:\n",
    "The model is trained using binary crossentropy loss and the Adam optimizer.\n",
    "Training is performed over multiple epochs, monitoring both training and validation performance.\n",
    "Early stopping may be implemented to prevent overfitting.\n",
    "- Evaluation:\n",
    "The trained model is evaluated on a separate test set to assess its performance on unseen data.\n",
    "Metrics such as accuracy, precision, recall, and F1 score are considered for comprehensive evaluation.\n",
    "- Prediction on New Data:\n",
    "The trained model is employed to make predictions on new images.\n",
    "Predictions are based on a defined threshold, classifying images as real or fake.\n",
    "### Results:\n",
    "\n",
    "- The model achieves an average accuracy of 50% and generalizes well to new data.\n",
    "- Regularization techniques contribute to preventing overfitting and enhancing model robustness.\n",
    "\n",
    "\n",
    "### Continuous monitoring and refinement of the model's performance on real-world data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09323dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
