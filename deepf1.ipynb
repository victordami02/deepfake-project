{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed46a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, concatenate, Reshape\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8981bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "        if path.endswith(\".jpg\") or path.endswith(\".png\"):\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            img = cv2.resize(img, (224, 224))  # Resize images to a common size\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96f7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(data_folder):\n",
    "        label_folder = os.path.join(data_folder, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            label_images, label_labels = load_images_from_folder(label_folder, label)\n",
    "            images.extend(label_images)\n",
    "            labels.extend(label_labels)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "739981d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "train_folder = '/Users/mac/Documents/clonerepo/Deep-Fake-Model/dataset/train/'\n",
    "val_folder = '/Users/mac/Documents/clonerepo/Deep-Fake-Model/dataset/validation/'\n",
    "test_folder = '/Users/mac/Documents/clonerepo/Deep-Fake-Model/dataset/test/'\n",
    "\n",
    "train_images, train_labels = load_dataset(train_folder)\n",
    "val_images, val_labels = load_dataset(val_folder)\n",
    "test_images, test_labels = load_dataset(test_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3ff66eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 43,  35,  24],\n",
       "         [ 43,  35,  24],\n",
       "         [ 43,  35,  24],\n",
       "         ...,\n",
       "         [ 42,  37,  23],\n",
       "         [ 42,  37,  23],\n",
       "         [ 42,  37,  23]],\n",
       "\n",
       "        [[ 43,  35,  24],\n",
       "         [ 43,  35,  24],\n",
       "         [ 43,  35,  24],\n",
       "         ...,\n",
       "         [ 42,  37,  23],\n",
       "         [ 44,  36,  23],\n",
       "         [ 44,  36,  23]],\n",
       "\n",
       "        [[ 43,  35,  24],\n",
       "         [ 43,  35,  24],\n",
       "         [ 43,  35,  24],\n",
       "         ...,\n",
       "         [ 42,  37,  23],\n",
       "         [ 44,  36,  23],\n",
       "         [ 44,  36,  23]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 33,  32,  21],\n",
       "         [ 33,  32,  23],\n",
       "         [ 33,  32,  23],\n",
       "         ...,\n",
       "         [ 35,  29,  20],\n",
       "         [ 35,  28,  18],\n",
       "         [ 35,  28,  18]],\n",
       "\n",
       "        [[ 33,  32,  25],\n",
       "         [ 33,  32,  25],\n",
       "         [ 33,  32,  25],\n",
       "         ...,\n",
       "         [ 33,  29,  23],\n",
       "         [ 34,  28,  21],\n",
       "         [ 34,  28,  21]],\n",
       "\n",
       "        [[ 33,  32,  25],\n",
       "         [ 33,  32,  25],\n",
       "         [ 33,  32,  25],\n",
       "         ...,\n",
       "         [ 33,  29,  23],\n",
       "         [ 34,  28,  21],\n",
       "         [ 34,  28,  21]]],\n",
       "\n",
       "\n",
       "       [[[ 44,  35,  20],\n",
       "         [ 45,  37,  21],\n",
       "         [ 45,  38,  23],\n",
       "         ...,\n",
       "         [ 38,  36,  18],\n",
       "         [ 37,  35,  17],\n",
       "         [ 36,  34,  16]],\n",
       "\n",
       "        [[ 44,  35,  20],\n",
       "         [ 45,  37,  21],\n",
       "         [ 45,  39,  22],\n",
       "         ...,\n",
       "         [ 38,  36,  18],\n",
       "         [ 37,  35,  17],\n",
       "         [ 36,  34,  16]],\n",
       "\n",
       "        [[ 44,  35,  20],\n",
       "         [ 45,  37,  21],\n",
       "         [ 46,  39,  23],\n",
       "         ...,\n",
       "         [ 38,  36,  18],\n",
       "         [ 37,  35,  17],\n",
       "         [ 36,  34,  16]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 35,  34,  27],\n",
       "         [ 35,  34,  27],\n",
       "         [ 35,  34,  27],\n",
       "         ...,\n",
       "         [ 35,  27,  15],\n",
       "         [ 35,  27,  16],\n",
       "         [ 34,  26,  15]],\n",
       "\n",
       "        [[ 35,  34,  27],\n",
       "         [ 35,  34,  27],\n",
       "         [ 35,  34,  27],\n",
       "         ...,\n",
       "         [ 35,  27,  16],\n",
       "         [ 35,  28,  17],\n",
       "         [ 35,  28,  17]],\n",
       "\n",
       "        [[ 35,  34,  27],\n",
       "         [ 35,  34,  27],\n",
       "         [ 35,  34,  27],\n",
       "         ...,\n",
       "         [ 33,  27,  18],\n",
       "         [ 34,  28,  19],\n",
       "         [ 34,  28,  19]]],\n",
       "\n",
       "\n",
       "       [[[ 33,  22,  15],\n",
       "         [ 33,  22,  15],\n",
       "         [ 33,  22,  15],\n",
       "         ...,\n",
       "         [ 66,  17,   6],\n",
       "         [ 64,  15,   4],\n",
       "         [ 60,  11,   0]],\n",
       "\n",
       "        [[ 33,  22,  15],\n",
       "         [ 33,  22,  15],\n",
       "         [ 33,  22,  15],\n",
       "         ...,\n",
       "         [ 82,  33,  22],\n",
       "         [ 77,  28,  18],\n",
       "         [ 77,  28,  18]],\n",
       "\n",
       "        [[ 33,  22,  15],\n",
       "         [ 33,  22,  15],\n",
       "         [ 33,  22,  15],\n",
       "         ...,\n",
       "         [116,  66,  39],\n",
       "         [112,  62,  35],\n",
       "         [112,  62,  35]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 65,  66,  18],\n",
       "         [ 65,  66,  18],\n",
       "         [ 65,  66,  18],\n",
       "         ...,\n",
       "         [ 52,  50,  19],\n",
       "         [ 51,  49,  18],\n",
       "         [ 50,  48,  17]],\n",
       "\n",
       "        [[ 65,  66,  18],\n",
       "         [ 65,  66,  18],\n",
       "         [ 65,  66,  18],\n",
       "         ...,\n",
       "         [ 52,  50,  19],\n",
       "         [ 51,  49,  18],\n",
       "         [ 50,  48,  17]],\n",
       "\n",
       "        [[ 65,  66,  18],\n",
       "         [ 65,  66,  18],\n",
       "         [ 65,  66,  18],\n",
       "         ...,\n",
       "         [ 52,  50,  19],\n",
       "         [ 51,  49,  18],\n",
       "         [ 50,  48,  17]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[227, 222, 228],\n",
       "         [227, 222, 228],\n",
       "         [230, 225, 231],\n",
       "         ...,\n",
       "         [231, 226, 145],\n",
       "         [236, 231, 149],\n",
       "         [226, 221, 139]],\n",
       "\n",
       "        [[231, 226, 232],\n",
       "         [231, 226, 232],\n",
       "         [232, 227, 233],\n",
       "         ...,\n",
       "         [231, 226, 145],\n",
       "         [235, 230, 148],\n",
       "         [224, 219, 137]],\n",
       "\n",
       "        [[233, 228, 234],\n",
       "         [232, 227, 233],\n",
       "         [233, 228, 234],\n",
       "         ...,\n",
       "         [233, 227, 145],\n",
       "         [235, 230, 148],\n",
       "         [228, 223, 141]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[160,  81,  36],\n",
       "         [159,  81,  34],\n",
       "         [158,  81,  33],\n",
       "         ...,\n",
       "         [ 33,  33,  35],\n",
       "         [ 36,  35,  40],\n",
       "         [ 39,  38,  43]],\n",
       "\n",
       "        [[156,  74,  35],\n",
       "         [153,  74,  33],\n",
       "         [151,  72,  30],\n",
       "         ...,\n",
       "         [ 31,  31,  33],\n",
       "         [ 35,  34,  39],\n",
       "         [ 39,  37,  43]],\n",
       "\n",
       "        [[150,  67,  32],\n",
       "         [146,  67,  29],\n",
       "         [145,  66,  27],\n",
       "         ...,\n",
       "         [ 30,  30,  32],\n",
       "         [ 35,  34,  39],\n",
       "         [ 38,  37,  42]]],\n",
       "\n",
       "\n",
       "       [[[201, 190, 126],\n",
       "         [209, 195, 134],\n",
       "         [219, 205, 145],\n",
       "         ...,\n",
       "         [232, 223, 140],\n",
       "         [233, 225, 142],\n",
       "         [234, 226, 143]],\n",
       "\n",
       "        [[202, 191, 127],\n",
       "         [209, 195, 134],\n",
       "         [218, 203, 145],\n",
       "         ...,\n",
       "         [223, 212, 130],\n",
       "         [229, 221, 138],\n",
       "         [232, 224, 141]],\n",
       "\n",
       "        [[202, 191, 129],\n",
       "         [209, 195, 134],\n",
       "         [218, 203, 145],\n",
       "         ...,\n",
       "         [205, 194, 111],\n",
       "         [222, 211, 129],\n",
       "         [233, 222, 139]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 36,  35,  43],\n",
       "         [ 36,  35,  43],\n",
       "         [ 36,  35,  43],\n",
       "         ...,\n",
       "         [161, 145,  85],\n",
       "         [171, 152,  93],\n",
       "         [172, 153,  93]],\n",
       "\n",
       "        [[ 36,  35,  43],\n",
       "         [ 35,  34,  42],\n",
       "         [ 35,  34,  42],\n",
       "         ...,\n",
       "         [159, 144,  88],\n",
       "         [174, 157, 101],\n",
       "         [178, 161, 104]],\n",
       "\n",
       "        [[ 36,  35,  41],\n",
       "         [ 35,  34,  40],\n",
       "         [ 34,  33,  39],\n",
       "         ...,\n",
       "         [162, 147,  93],\n",
       "         [178, 163, 108],\n",
       "         [181, 166, 111]]],\n",
       "\n",
       "\n",
       "       [[[201, 191, 119],\n",
       "         [199, 190, 115],\n",
       "         [207, 198, 123],\n",
       "         ...,\n",
       "         [145, 126,  99],\n",
       "         [147, 126,  97],\n",
       "         [150, 129,  98]],\n",
       "\n",
       "        [[211, 200, 128],\n",
       "         [199, 190, 115],\n",
       "         [199, 190, 115],\n",
       "         ...,\n",
       "         [147, 128, 102],\n",
       "         [145, 124,  97],\n",
       "         [147, 126,  97]],\n",
       "\n",
       "        [[214, 204, 132],\n",
       "         [207, 197, 123],\n",
       "         [201, 193, 117],\n",
       "         ...,\n",
       "         [153, 133, 109],\n",
       "         [152, 130, 106],\n",
       "         [152, 131, 105]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[137,  30,  24],\n",
       "         [131,  24,  17],\n",
       "         [129,  22,  16],\n",
       "         ...,\n",
       "         [223, 217, 217],\n",
       "         [223, 218, 218],\n",
       "         [221, 216, 215]],\n",
       "\n",
       "        [[140,  33,  27],\n",
       "         [132,  25,  19],\n",
       "         [128,  20,  17],\n",
       "         ...,\n",
       "         [224, 218, 218],\n",
       "         [224, 218, 218],\n",
       "         [222, 216, 216]],\n",
       "\n",
       "        [[138,  30,  24],\n",
       "         [132,  24,  21],\n",
       "         [128,  20,  17],\n",
       "         ...,\n",
       "         [223, 217, 217],\n",
       "         [224, 218, 218],\n",
       "         [222, 217, 217]]]], dtype=uint8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfaf5e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake'], dtype='<U4')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adb0630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training set\n",
    "# train_images, train_labels = shuffle(train_images, train_labels, random_state=42)\n",
    "\n",
    "# Normalize pixel values\n",
    "train_images = train_images / 255.0\n",
    "val_images = val_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e58147b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.16862745, 0.1372549 , 0.09411765],\n",
       "         [0.16862745, 0.1372549 , 0.09411765],\n",
       "         [0.16862745, 0.1372549 , 0.09411765],\n",
       "         ...,\n",
       "         [0.16470588, 0.14509804, 0.09019608],\n",
       "         [0.16470588, 0.14509804, 0.09019608],\n",
       "         [0.16470588, 0.14509804, 0.09019608]],\n",
       "\n",
       "        [[0.16862745, 0.1372549 , 0.09411765],\n",
       "         [0.16862745, 0.1372549 , 0.09411765],\n",
       "         [0.16862745, 0.1372549 , 0.09411765],\n",
       "         ...,\n",
       "         [0.16470588, 0.14509804, 0.09019608],\n",
       "         [0.17254902, 0.14117647, 0.09019608],\n",
       "         [0.17254902, 0.14117647, 0.09019608]],\n",
       "\n",
       "        [[0.16862745, 0.1372549 , 0.09411765],\n",
       "         [0.16862745, 0.1372549 , 0.09411765],\n",
       "         [0.16862745, 0.1372549 , 0.09411765],\n",
       "         ...,\n",
       "         [0.16470588, 0.14509804, 0.09019608],\n",
       "         [0.17254902, 0.14117647, 0.09019608],\n",
       "         [0.17254902, 0.14117647, 0.09019608]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.12941176, 0.1254902 , 0.08235294],\n",
       "         [0.12941176, 0.1254902 , 0.09019608],\n",
       "         [0.12941176, 0.1254902 , 0.09019608],\n",
       "         ...,\n",
       "         [0.1372549 , 0.11372549, 0.07843137],\n",
       "         [0.1372549 , 0.10980392, 0.07058824],\n",
       "         [0.1372549 , 0.10980392, 0.07058824]],\n",
       "\n",
       "        [[0.12941176, 0.1254902 , 0.09803922],\n",
       "         [0.12941176, 0.1254902 , 0.09803922],\n",
       "         [0.12941176, 0.1254902 , 0.09803922],\n",
       "         ...,\n",
       "         [0.12941176, 0.11372549, 0.09019608],\n",
       "         [0.13333333, 0.10980392, 0.08235294],\n",
       "         [0.13333333, 0.10980392, 0.08235294]],\n",
       "\n",
       "        [[0.12941176, 0.1254902 , 0.09803922],\n",
       "         [0.12941176, 0.1254902 , 0.09803922],\n",
       "         [0.12941176, 0.1254902 , 0.09803922],\n",
       "         ...,\n",
       "         [0.12941176, 0.11372549, 0.09019608],\n",
       "         [0.13333333, 0.10980392, 0.08235294],\n",
       "         [0.13333333, 0.10980392, 0.08235294]]],\n",
       "\n",
       "\n",
       "       [[[0.17254902, 0.1372549 , 0.07843137],\n",
       "         [0.17647059, 0.14509804, 0.08235294],\n",
       "         [0.17647059, 0.14901961, 0.09019608],\n",
       "         ...,\n",
       "         [0.14901961, 0.14117647, 0.07058824],\n",
       "         [0.14509804, 0.1372549 , 0.06666667],\n",
       "         [0.14117647, 0.13333333, 0.0627451 ]],\n",
       "\n",
       "        [[0.17254902, 0.1372549 , 0.07843137],\n",
       "         [0.17647059, 0.14509804, 0.08235294],\n",
       "         [0.17647059, 0.15294118, 0.08627451],\n",
       "         ...,\n",
       "         [0.14901961, 0.14117647, 0.07058824],\n",
       "         [0.14509804, 0.1372549 , 0.06666667],\n",
       "         [0.14117647, 0.13333333, 0.0627451 ]],\n",
       "\n",
       "        [[0.17254902, 0.1372549 , 0.07843137],\n",
       "         [0.17647059, 0.14509804, 0.08235294],\n",
       "         [0.18039216, 0.15294118, 0.09019608],\n",
       "         ...,\n",
       "         [0.14901961, 0.14117647, 0.07058824],\n",
       "         [0.14509804, 0.1372549 , 0.06666667],\n",
       "         [0.14117647, 0.13333333, 0.0627451 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1372549 , 0.13333333, 0.10588235],\n",
       "         [0.1372549 , 0.13333333, 0.10588235],\n",
       "         [0.1372549 , 0.13333333, 0.10588235],\n",
       "         ...,\n",
       "         [0.1372549 , 0.10588235, 0.05882353],\n",
       "         [0.1372549 , 0.10588235, 0.0627451 ],\n",
       "         [0.13333333, 0.10196078, 0.05882353]],\n",
       "\n",
       "        [[0.1372549 , 0.13333333, 0.10588235],\n",
       "         [0.1372549 , 0.13333333, 0.10588235],\n",
       "         [0.1372549 , 0.13333333, 0.10588235],\n",
       "         ...,\n",
       "         [0.1372549 , 0.10588235, 0.0627451 ],\n",
       "         [0.1372549 , 0.10980392, 0.06666667],\n",
       "         [0.1372549 , 0.10980392, 0.06666667]],\n",
       "\n",
       "        [[0.1372549 , 0.13333333, 0.10588235],\n",
       "         [0.1372549 , 0.13333333, 0.10588235],\n",
       "         [0.1372549 , 0.13333333, 0.10588235],\n",
       "         ...,\n",
       "         [0.12941176, 0.10588235, 0.07058824],\n",
       "         [0.13333333, 0.10980392, 0.0745098 ],\n",
       "         [0.13333333, 0.10980392, 0.0745098 ]]],\n",
       "\n",
       "\n",
       "       [[[0.12941176, 0.08627451, 0.05882353],\n",
       "         [0.12941176, 0.08627451, 0.05882353],\n",
       "         [0.12941176, 0.08627451, 0.05882353],\n",
       "         ...,\n",
       "         [0.25882353, 0.06666667, 0.02352941],\n",
       "         [0.25098039, 0.05882353, 0.01568627],\n",
       "         [0.23529412, 0.04313725, 0.        ]],\n",
       "\n",
       "        [[0.12941176, 0.08627451, 0.05882353],\n",
       "         [0.12941176, 0.08627451, 0.05882353],\n",
       "         [0.12941176, 0.08627451, 0.05882353],\n",
       "         ...,\n",
       "         [0.32156863, 0.12941176, 0.08627451],\n",
       "         [0.30196078, 0.10980392, 0.07058824],\n",
       "         [0.30196078, 0.10980392, 0.07058824]],\n",
       "\n",
       "        [[0.12941176, 0.08627451, 0.05882353],\n",
       "         [0.12941176, 0.08627451, 0.05882353],\n",
       "         [0.12941176, 0.08627451, 0.05882353],\n",
       "         ...,\n",
       "         [0.45490196, 0.25882353, 0.15294118],\n",
       "         [0.43921569, 0.24313725, 0.1372549 ],\n",
       "         [0.43921569, 0.24313725, 0.1372549 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.25490196, 0.25882353, 0.07058824],\n",
       "         [0.25490196, 0.25882353, 0.07058824],\n",
       "         [0.25490196, 0.25882353, 0.07058824],\n",
       "         ...,\n",
       "         [0.20392157, 0.19607843, 0.0745098 ],\n",
       "         [0.2       , 0.19215686, 0.07058824],\n",
       "         [0.19607843, 0.18823529, 0.06666667]],\n",
       "\n",
       "        [[0.25490196, 0.25882353, 0.07058824],\n",
       "         [0.25490196, 0.25882353, 0.07058824],\n",
       "         [0.25490196, 0.25882353, 0.07058824],\n",
       "         ...,\n",
       "         [0.20392157, 0.19607843, 0.0745098 ],\n",
       "         [0.2       , 0.19215686, 0.07058824],\n",
       "         [0.19607843, 0.18823529, 0.06666667]],\n",
       "\n",
       "        [[0.25490196, 0.25882353, 0.07058824],\n",
       "         [0.25490196, 0.25882353, 0.07058824],\n",
       "         [0.25490196, 0.25882353, 0.07058824],\n",
       "         ...,\n",
       "         [0.20392157, 0.19607843, 0.0745098 ],\n",
       "         [0.2       , 0.19215686, 0.07058824],\n",
       "         [0.19607843, 0.18823529, 0.06666667]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.89019608, 0.87058824, 0.89411765],\n",
       "         [0.89019608, 0.87058824, 0.89411765],\n",
       "         [0.90196078, 0.88235294, 0.90588235],\n",
       "         ...,\n",
       "         [0.90588235, 0.88627451, 0.56862745],\n",
       "         [0.9254902 , 0.90588235, 0.58431373],\n",
       "         [0.88627451, 0.86666667, 0.54509804]],\n",
       "\n",
       "        [[0.90588235, 0.88627451, 0.90980392],\n",
       "         [0.90588235, 0.88627451, 0.90980392],\n",
       "         [0.90980392, 0.89019608, 0.91372549],\n",
       "         ...,\n",
       "         [0.90588235, 0.88627451, 0.56862745],\n",
       "         [0.92156863, 0.90196078, 0.58039216],\n",
       "         [0.87843137, 0.85882353, 0.5372549 ]],\n",
       "\n",
       "        [[0.91372549, 0.89411765, 0.91764706],\n",
       "         [0.90980392, 0.89019608, 0.91372549],\n",
       "         [0.91372549, 0.89411765, 0.91764706],\n",
       "         ...,\n",
       "         [0.91372549, 0.89019608, 0.56862745],\n",
       "         [0.92156863, 0.90196078, 0.58039216],\n",
       "         [0.89411765, 0.8745098 , 0.55294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.62745098, 0.31764706, 0.14117647],\n",
       "         [0.62352941, 0.31764706, 0.13333333],\n",
       "         [0.61960784, 0.31764706, 0.12941176],\n",
       "         ...,\n",
       "         [0.12941176, 0.12941176, 0.1372549 ],\n",
       "         [0.14117647, 0.1372549 , 0.15686275],\n",
       "         [0.15294118, 0.14901961, 0.16862745]],\n",
       "\n",
       "        [[0.61176471, 0.29019608, 0.1372549 ],\n",
       "         [0.6       , 0.29019608, 0.12941176],\n",
       "         [0.59215686, 0.28235294, 0.11764706],\n",
       "         ...,\n",
       "         [0.12156863, 0.12156863, 0.12941176],\n",
       "         [0.1372549 , 0.13333333, 0.15294118],\n",
       "         [0.15294118, 0.14509804, 0.16862745]],\n",
       "\n",
       "        [[0.58823529, 0.2627451 , 0.1254902 ],\n",
       "         [0.57254902, 0.2627451 , 0.11372549],\n",
       "         [0.56862745, 0.25882353, 0.10588235],\n",
       "         ...,\n",
       "         [0.11764706, 0.11764706, 0.1254902 ],\n",
       "         [0.1372549 , 0.13333333, 0.15294118],\n",
       "         [0.14901961, 0.14509804, 0.16470588]]],\n",
       "\n",
       "\n",
       "       [[[0.78823529, 0.74509804, 0.49411765],\n",
       "         [0.81960784, 0.76470588, 0.5254902 ],\n",
       "         [0.85882353, 0.80392157, 0.56862745],\n",
       "         ...,\n",
       "         [0.90980392, 0.8745098 , 0.54901961],\n",
       "         [0.91372549, 0.88235294, 0.55686275],\n",
       "         [0.91764706, 0.88627451, 0.56078431]],\n",
       "\n",
       "        [[0.79215686, 0.74901961, 0.49803922],\n",
       "         [0.81960784, 0.76470588, 0.5254902 ],\n",
       "         [0.85490196, 0.79607843, 0.56862745],\n",
       "         ...,\n",
       "         [0.8745098 , 0.83137255, 0.50980392],\n",
       "         [0.89803922, 0.86666667, 0.54117647],\n",
       "         [0.90980392, 0.87843137, 0.55294118]],\n",
       "\n",
       "        [[0.79215686, 0.74901961, 0.50588235],\n",
       "         [0.81960784, 0.76470588, 0.5254902 ],\n",
       "         [0.85490196, 0.79607843, 0.56862745],\n",
       "         ...,\n",
       "         [0.80392157, 0.76078431, 0.43529412],\n",
       "         [0.87058824, 0.82745098, 0.50588235],\n",
       "         [0.91372549, 0.87058824, 0.54509804]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.14117647, 0.1372549 , 0.16862745],\n",
       "         [0.14117647, 0.1372549 , 0.16862745],\n",
       "         [0.14117647, 0.1372549 , 0.16862745],\n",
       "         ...,\n",
       "         [0.63137255, 0.56862745, 0.33333333],\n",
       "         [0.67058824, 0.59607843, 0.36470588],\n",
       "         [0.6745098 , 0.6       , 0.36470588]],\n",
       "\n",
       "        [[0.14117647, 0.1372549 , 0.16862745],\n",
       "         [0.1372549 , 0.13333333, 0.16470588],\n",
       "         [0.1372549 , 0.13333333, 0.16470588],\n",
       "         ...,\n",
       "         [0.62352941, 0.56470588, 0.34509804],\n",
       "         [0.68235294, 0.61568627, 0.39607843],\n",
       "         [0.69803922, 0.63137255, 0.40784314]],\n",
       "\n",
       "        [[0.14117647, 0.1372549 , 0.16078431],\n",
       "         [0.1372549 , 0.13333333, 0.15686275],\n",
       "         [0.13333333, 0.12941176, 0.15294118],\n",
       "         ...,\n",
       "         [0.63529412, 0.57647059, 0.36470588],\n",
       "         [0.69803922, 0.63921569, 0.42352941],\n",
       "         [0.70980392, 0.65098039, 0.43529412]]],\n",
       "\n",
       "\n",
       "       [[[0.78823529, 0.74901961, 0.46666667],\n",
       "         [0.78039216, 0.74509804, 0.45098039],\n",
       "         [0.81176471, 0.77647059, 0.48235294],\n",
       "         ...,\n",
       "         [0.56862745, 0.49411765, 0.38823529],\n",
       "         [0.57647059, 0.49411765, 0.38039216],\n",
       "         [0.58823529, 0.50588235, 0.38431373]],\n",
       "\n",
       "        [[0.82745098, 0.78431373, 0.50196078],\n",
       "         [0.78039216, 0.74509804, 0.45098039],\n",
       "         [0.78039216, 0.74509804, 0.45098039],\n",
       "         ...,\n",
       "         [0.57647059, 0.50196078, 0.4       ],\n",
       "         [0.56862745, 0.48627451, 0.38039216],\n",
       "         [0.57647059, 0.49411765, 0.38039216]],\n",
       "\n",
       "        [[0.83921569, 0.8       , 0.51764706],\n",
       "         [0.81176471, 0.77254902, 0.48235294],\n",
       "         [0.78823529, 0.75686275, 0.45882353],\n",
       "         ...,\n",
       "         [0.6       , 0.52156863, 0.42745098],\n",
       "         [0.59607843, 0.50980392, 0.41568627],\n",
       "         [0.59607843, 0.51372549, 0.41176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5372549 , 0.11764706, 0.09411765],\n",
       "         [0.51372549, 0.09411765, 0.06666667],\n",
       "         [0.50588235, 0.08627451, 0.0627451 ],\n",
       "         ...,\n",
       "         [0.8745098 , 0.85098039, 0.85098039],\n",
       "         [0.8745098 , 0.85490196, 0.85490196],\n",
       "         [0.86666667, 0.84705882, 0.84313725]],\n",
       "\n",
       "        [[0.54901961, 0.12941176, 0.10588235],\n",
       "         [0.51764706, 0.09803922, 0.0745098 ],\n",
       "         [0.50196078, 0.07843137, 0.06666667],\n",
       "         ...,\n",
       "         [0.87843137, 0.85490196, 0.85490196],\n",
       "         [0.87843137, 0.85490196, 0.85490196],\n",
       "         [0.87058824, 0.84705882, 0.84705882]],\n",
       "\n",
       "        [[0.54117647, 0.11764706, 0.09411765],\n",
       "         [0.51764706, 0.09411765, 0.08235294],\n",
       "         [0.50196078, 0.07843137, 0.06666667],\n",
       "         ...,\n",
       "         [0.8745098 , 0.85098039, 0.85098039],\n",
       "         [0.87843137, 0.85490196, 0.85490196],\n",
       "         [0.87058824, 0.85098039, 0.85098039]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "464f3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = to_categorical(label_encoder.fit_transform(train_labels))\n",
    "y_test_encoded = to_categorical(label_encoder.transform(test_labels))\n",
    "y_val_encoded = to_categorical(label_encoder.transform(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9aefe63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dbbd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ec1c35a",
   "metadata": {},
   "source": [
    "# Training with CNN VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7b100e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 58s 5s/step - loss: 8.8385 - accuracy: 0.8292 - val_loss: 0.0258 - val_accuracy: 0.9932\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 58s 5s/step - loss: 0.1469 - accuracy: 0.9950 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9865\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 56s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.8716\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7853 - val_accuracy: 0.8378\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 57s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.8108\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 58s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9085 - val_accuracy: 0.8108\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 57s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9161 - val_accuracy: 0.8108\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 58s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9181 - val_accuracy: 0.8108\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 57s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9187 - val_accuracy: 0.8108\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "# Define VGG16 model\n",
    "vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze layers to prevent training on ImageNet weights\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Flatten VGG output\n",
    "flattened_vgg_output = Flatten()(vgg_model.output)\n",
    "\n",
    "# Add dense layers for classification\n",
    "x = Dense(128, activation='relu')(flattened_vgg_output)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "image_only_model = Model(inputs=vgg_model.input, outputs=output)\n",
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps=1000, decay_rate=0.9)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "image_only_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10  # You can adjust the number of epochs as needed\n",
    "batch_size = 32  # You can adjust the batch size as needed\n",
    "\n",
    "\n",
    "\n",
    "# Rest of your code...\n",
    "\n",
    "# Train the model\n",
    "image_only_model.fit(\n",
    "    train_images,\n",
    "    y_train_encoded,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(val_images, y_val_encoded)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = image_only_model.evaluate(test_images, y_test_encoded)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9721b",
   "metadata": {},
   "source": [
    "## Prediction on a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46770e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data= '/Users/mac/Documents/clonerepo/Deep-Fake-Model/modi/dataset/test/'\n",
    "newdata_images, new_data_labels = load_dataset(new_data)\n",
    "\n",
    "#predictions = image_only_model.predict(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2eae7508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real',\n",
       "       'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake',\n",
       "       'fake', 'fake', 'fake', 'fake'], dtype='<U4')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98a5040a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.45098039, 0.34117647, 0.32156863],\n",
       "         [0.43921569, 0.3372549 , 0.30196078],\n",
       "         [0.43529412, 0.32941176, 0.28627451],\n",
       "         ...,\n",
       "         [0.78039216, 0.71764706, 0.60392157],\n",
       "         [0.77254902, 0.70980392, 0.59215686],\n",
       "         [0.76470588, 0.70196078, 0.57254902]],\n",
       "\n",
       "        [[0.44313725, 0.33333333, 0.31764706],\n",
       "         [0.44313725, 0.3372549 , 0.30588235],\n",
       "         [0.44313725, 0.3372549 , 0.29019608],\n",
       "         ...,\n",
       "         [0.78823529, 0.72941176, 0.61568627],\n",
       "         [0.78431373, 0.7254902 , 0.60392157],\n",
       "         [0.77647059, 0.71372549, 0.58823529]],\n",
       "\n",
       "        [[0.42745098, 0.31764706, 0.30196078],\n",
       "         [0.43529412, 0.32941176, 0.29411765],\n",
       "         [0.44313725, 0.3372549 , 0.29019608],\n",
       "         ...,\n",
       "         [0.78823529, 0.72941176, 0.61176471],\n",
       "         [0.79607843, 0.73333333, 0.62352941],\n",
       "         [0.79215686, 0.7254902 , 0.61568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.51372549, 0.37647059, 0.36078431],\n",
       "         [0.50980392, 0.35686275, 0.32941176],\n",
       "         [0.52156863, 0.35294118, 0.31764706],\n",
       "         ...,\n",
       "         [0.65490196, 0.45098039, 0.31764706],\n",
       "         [0.66666667, 0.45882353, 0.32941176],\n",
       "         [0.6745098 , 0.46666667, 0.34117647]],\n",
       "\n",
       "        [[0.50980392, 0.37254902, 0.35686275],\n",
       "         [0.50588235, 0.35294118, 0.3254902 ],\n",
       "         [0.51764706, 0.34901961, 0.31372549],\n",
       "         ...,\n",
       "         [0.66666667, 0.4627451 , 0.31764706],\n",
       "         [0.67058824, 0.46666667, 0.3254902 ],\n",
       "         [0.6745098 , 0.46666667, 0.34117647]],\n",
       "\n",
       "        [[0.50588235, 0.36862745, 0.35294118],\n",
       "         [0.50196078, 0.34901961, 0.3254902 ],\n",
       "         [0.51372549, 0.34509804, 0.30980392],\n",
       "         ...,\n",
       "         [0.6745098 , 0.47058824, 0.31764706],\n",
       "         [0.67058824, 0.46666667, 0.32156863],\n",
       "         [0.67843137, 0.47058824, 0.34509804]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.58039216, 0.45882353, 0.3372549 ],\n",
       "         [0.57254902, 0.45098039, 0.32941176],\n",
       "         [0.55686275, 0.43529412, 0.31372549]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.57647059, 0.45490196, 0.33333333],\n",
       "         [0.57254902, 0.45098039, 0.32941176],\n",
       "         [0.55686275, 0.43529412, 0.31372549]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.56470588, 0.44313725, 0.3254902 ],\n",
       "         [0.56862745, 0.44705882, 0.3254902 ],\n",
       "         [0.56862745, 0.44705882, 0.3254902 ]]],\n",
       "\n",
       "\n",
       "       [[[0.04313725, 0.03921569, 0.01960784],\n",
       "         [0.04705882, 0.04313725, 0.02352941],\n",
       "         [0.05098039, 0.04705882, 0.02745098],\n",
       "         ...,\n",
       "         [0.0627451 , 0.04313725, 0.03137255],\n",
       "         [0.0627451 , 0.04313725, 0.03137255],\n",
       "         [0.0627451 , 0.04313725, 0.03137255]],\n",
       "\n",
       "        [[0.04313725, 0.03921569, 0.01960784],\n",
       "         [0.04705882, 0.04313725, 0.02352941],\n",
       "         [0.05098039, 0.04705882, 0.02745098],\n",
       "         ...,\n",
       "         [0.0627451 , 0.04313725, 0.03137255],\n",
       "         [0.0627451 , 0.04313725, 0.03137255],\n",
       "         [0.0627451 , 0.04313725, 0.03137255]],\n",
       "\n",
       "        [[0.03921569, 0.03921569, 0.01960784],\n",
       "         [0.04313725, 0.03921569, 0.01960784],\n",
       "         [0.05098039, 0.04313725, 0.02352941],\n",
       "         ...,\n",
       "         [0.0627451 , 0.04313725, 0.03137255],\n",
       "         [0.0627451 , 0.04313725, 0.03137255],\n",
       "         [0.0627451 , 0.04313725, 0.03137255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.07058824, 0.07058824, 0.07058824],\n",
       "         [0.0627451 , 0.06666667, 0.0627451 ],\n",
       "         [0.05098039, 0.05098039, 0.05098039],\n",
       "         ...,\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784]],\n",
       "\n",
       "        [[0.07058824, 0.07058824, 0.07058824],\n",
       "         [0.06666667, 0.06666667, 0.06666667],\n",
       "         [0.05490196, 0.05490196, 0.05490196],\n",
       "         ...,\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784]],\n",
       "\n",
       "        [[0.0745098 , 0.0745098 , 0.0745098 ],\n",
       "         [0.06666667, 0.06666667, 0.06666667],\n",
       "         [0.05490196, 0.05490196, 0.05490196],\n",
       "         ...,\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.01960784, 0.01960784, 0.01960784]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.05490196, 0.05490196, 0.02745098],\n",
       "         [0.0627451 , 0.06666667, 0.01960784],\n",
       "         [0.08235294, 0.08235294, 0.0627451 ],\n",
       "         ...,\n",
       "         [0.05490196, 0.05490196, 0.03529412],\n",
       "         [0.0627451 , 0.0627451 , 0.03529412],\n",
       "         [0.0627451 , 0.06666667, 0.03529412]],\n",
       "\n",
       "        [[0.05490196, 0.05490196, 0.02745098],\n",
       "         [0.0627451 , 0.06666667, 0.02352941],\n",
       "         [0.07843137, 0.07843137, 0.05882353],\n",
       "         ...,\n",
       "         [0.05882353, 0.05882353, 0.03921569],\n",
       "         [0.0627451 , 0.0627451 , 0.03529412],\n",
       "         [0.0627451 , 0.06666667, 0.03529412]],\n",
       "\n",
       "        [[0.04705882, 0.04705882, 0.01960784],\n",
       "         [0.05882353, 0.06666667, 0.01960784],\n",
       "         [0.07843137, 0.07843137, 0.05882353],\n",
       "         ...,\n",
       "         [0.07058824, 0.07058824, 0.05098039],\n",
       "         [0.0627451 , 0.06666667, 0.03137255],\n",
       "         [0.0627451 , 0.06666667, 0.02745098]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.22745098, 0.05882353, 0.        ],\n",
       "         [0.25098039, 0.04705882, 0.        ],\n",
       "         [0.23137255, 0.03921569, 0.        ],\n",
       "         ...,\n",
       "         [0.16078431, 0.09803922, 0.0745098 ],\n",
       "         [0.10196078, 0.00784314, 0.        ],\n",
       "         [0.11372549, 0.03529412, 0.02745098]],\n",
       "\n",
       "        [[0.22352941, 0.05490196, 0.        ],\n",
       "         [0.25490196, 0.05098039, 0.        ],\n",
       "         [0.23529412, 0.04313725, 0.        ],\n",
       "         ...,\n",
       "         [0.12941176, 0.03921569, 0.02745098],\n",
       "         [0.0745098 , 0.00784314, 0.        ],\n",
       "         [0.23529412, 0.18039216, 0.16078431]],\n",
       "\n",
       "        [[0.22745098, 0.05882353, 0.        ],\n",
       "         [0.2627451 , 0.05490196, 0.00784314],\n",
       "         [0.23529412, 0.04313725, 0.        ],\n",
       "         ...,\n",
       "         [0.11372549, 0.00392157, 0.        ],\n",
       "         [0.07843137, 0.01568627, 0.00392157],\n",
       "         [0.21176471, 0.16078431, 0.14117647]]],\n",
       "\n",
       "\n",
       "       [[[0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.23921569, 0.35686275, 0.51372549],\n",
       "         [0.23921569, 0.35686275, 0.51372549],\n",
       "         [0.23921569, 0.35686275, 0.51372549]],\n",
       "\n",
       "        [[0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.23529412, 0.35686275, 0.50980392],\n",
       "         [0.23921569, 0.35686275, 0.51372549],\n",
       "         [0.23921569, 0.35686275, 0.50588235]],\n",
       "\n",
       "        [[0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.23529412, 0.35294118, 0.50980392],\n",
       "         [0.23921569, 0.35686275, 0.51372549],\n",
       "         [0.23921569, 0.35686275, 0.50588235]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         ...,\n",
       "         [0.37647059, 0.34117647, 0.2745098 ],\n",
       "         [0.37647059, 0.34117647, 0.2745098 ],\n",
       "         [0.37647059, 0.34117647, 0.2745098 ]],\n",
       "\n",
       "        [[0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         ...,\n",
       "         [0.37647059, 0.34117647, 0.2745098 ],\n",
       "         [0.37647059, 0.34117647, 0.2745098 ],\n",
       "         [0.37647059, 0.34117647, 0.2745098 ]],\n",
       "\n",
       "        [[0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         ...,\n",
       "         [0.38431373, 0.34117647, 0.2745098 ],\n",
       "         [0.38431373, 0.34117647, 0.2745098 ],\n",
       "         [0.38431373, 0.34117647, 0.2745098 ]]],\n",
       "\n",
       "\n",
       "       [[[0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.23921569, 0.35686275, 0.51372549],\n",
       "         [0.23921569, 0.35686275, 0.51372549],\n",
       "         [0.23921569, 0.35686275, 0.51372549]],\n",
       "\n",
       "        [[0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.23529412, 0.35294118, 0.50980392],\n",
       "         [0.23921569, 0.35686275, 0.51372549],\n",
       "         [0.23921569, 0.35686275, 0.50588235]],\n",
       "\n",
       "        [[0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         [0.22745098, 0.34901961, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.23529412, 0.35294118, 0.50980392],\n",
       "         [0.23529412, 0.35294118, 0.50980392],\n",
       "         [0.23921569, 0.35686275, 0.50588235]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         ...,\n",
       "         [0.37647059, 0.34117647, 0.2745098 ],\n",
       "         [0.37647059, 0.34117647, 0.2745098 ],\n",
       "         [0.37647059, 0.34117647, 0.2745098 ]],\n",
       "\n",
       "        [[0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         ...,\n",
       "         [0.37647059, 0.34117647, 0.2745098 ],\n",
       "         [0.37647059, 0.34117647, 0.2745098 ],\n",
       "         [0.37647059, 0.34117647, 0.2745098 ]],\n",
       "\n",
       "        [[0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         [0.37254902, 0.3372549 , 0.27058824],\n",
       "         ...,\n",
       "         [0.38431373, 0.34117647, 0.2745098 ],\n",
       "         [0.38431373, 0.34117647, 0.2745098 ],\n",
       "         [0.38431373, 0.34117647, 0.2745098 ]]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata_images = newdata_images / 255.0\n",
    "newdata_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26a92c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 7s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = image_only_model.predict(newdata_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f49410f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.24201668e-05, 9.99907553e-01],\n",
       "       [1.20811033e-04, 9.99879062e-01],\n",
       "       [4.99780738e-11, 9.99999940e-01],\n",
       "       [2.73550256e-07, 9.99999702e-01],\n",
       "       [2.18488228e-09, 9.99999940e-01],\n",
       "       [2.67098835e-06, 9.99997318e-01],\n",
       "       [6.69304371e-01, 3.30695480e-01],\n",
       "       [2.14199876e-08, 9.99999940e-01],\n",
       "       [3.10868842e-07, 9.99999583e-01],\n",
       "       [5.71652026e-06, 9.99994218e-01],\n",
       "       [7.55303446e-08, 9.99999821e-01],\n",
       "       [1.69131876e-04, 9.99830961e-01],\n",
       "       [1.52998192e-09, 9.99999940e-01],\n",
       "       [1.06875619e-08, 9.99999940e-01],\n",
       "       [1.01866185e-07, 9.99999821e-01],\n",
       "       [4.98422969e-06, 9.99994934e-01],\n",
       "       [5.78306015e-07, 9.99999344e-01],\n",
       "       [9.09797848e-10, 9.99999940e-01],\n",
       "       [9.44670209e-09, 9.99999940e-01],\n",
       "       [1.34913847e-07, 9.99999821e-01],\n",
       "       [7.09513233e-06, 9.99992788e-01],\n",
       "       [8.15143250e-03, 9.91848528e-01],\n",
       "       [2.11995371e-07, 9.99999702e-01],\n",
       "       [1.64720780e-06, 9.99998271e-01],\n",
       "       [3.25515447e-03, 9.96744871e-01],\n",
       "       [1.08913149e-07, 9.99999821e-01],\n",
       "       [1.27058364e-09, 9.99999940e-01],\n",
       "       [1.43494432e-07, 9.99999821e-01],\n",
       "       [1.79946966e-07, 9.99999702e-01],\n",
       "       [1.93742494e-07, 9.99999702e-01],\n",
       "       [3.83527023e-08, 9.99999940e-01],\n",
       "       [1.06171614e-08, 9.99999940e-01],\n",
       "       [3.77146954e-08, 9.99999940e-01],\n",
       "       [1.95547528e-07, 9.99999702e-01],\n",
       "       [5.39663390e-08, 9.99999940e-01],\n",
       "       [2.18833973e-09, 9.99999940e-01],\n",
       "       [3.67421308e-06, 9.99996245e-01],\n",
       "       [1.76422326e-08, 9.99999940e-01],\n",
       "       [1.77310477e-09, 9.99999940e-01],\n",
       "       [1.70944736e-09, 9.99999940e-01],\n",
       "       [1.89699900e-09, 9.99999940e-01],\n",
       "       [1.41377443e-09, 9.99999940e-01],\n",
       "       [1.77328741e-09, 9.99999940e-01],\n",
       "       [1.81482385e-09, 9.99999940e-01],\n",
       "       [2.81058121e-02, 9.71894205e-01],\n",
       "       [3.00585013e-02, 9.69941556e-01],\n",
       "       [1.33260691e-09, 9.99999940e-01],\n",
       "       [5.36584253e-08, 9.99999940e-01],\n",
       "       [4.96467578e-08, 9.99999940e-01],\n",
       "       [1.29332034e-09, 9.99999940e-01],\n",
       "       [1.59365066e-09, 9.99999940e-01],\n",
       "       [5.07925044e-08, 9.99999940e-01],\n",
       "       [8.73415530e-01, 1.26584381e-01],\n",
       "       [3.06877851e-01, 6.93122089e-01],\n",
       "       [5.01582598e-08, 9.99999940e-01],\n",
       "       [1.67409586e-09, 9.99999940e-01],\n",
       "       [1.54973323e-09, 9.99999940e-01],\n",
       "       [4.91035586e-08, 9.99999940e-01],\n",
       "       [1.01527877e-01, 8.98472071e-01],\n",
       "       [4.69597978e-08, 9.99999940e-01],\n",
       "       [2.25956720e-09, 9.99999940e-01],\n",
       "       [6.98968215e-05, 9.99930084e-01],\n",
       "       [2.54996531e-02, 9.74500299e-01],\n",
       "       [1.36377905e-02, 9.86362219e-01],\n",
       "       [6.91517635e-05, 9.99930799e-01],\n",
       "       [1.17601262e-09, 9.99999940e-01],\n",
       "       [1.56674170e-04, 9.99843359e-01],\n",
       "       [4.07013558e-02, 9.59298551e-01],\n",
       "       [2.24697627e-02, 9.77530122e-01],\n",
       "       [4.75622173e-08, 9.99999940e-01],\n",
       "       [2.51688325e-04, 9.99748349e-01],\n",
       "       [1.43729595e-09, 9.99999940e-01],\n",
       "       [1.99802841e-09, 1.00000000e+00],\n",
       "       [5.34331264e-08, 1.00000000e+00],\n",
       "       [1.78100223e-09, 1.00000000e+00],\n",
       "       [1.48311019e-09, 1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb3f9513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Binary classification\n",
    "threshold = 0.5  # Adjust the threshold based on your needs\n",
    "\n",
    "binary_predictions = (predictions > threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb6315be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7526eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map binary labels to 'Real' or 'Fake'\n",
    "class_labels = ['Real', 'Fake']\n",
    "mapped_predictions = [class_labels[prediction] for prediction in binary_predictions.flatten()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42638279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake',\n",
       " 'Real',\n",
       " 'Fake']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682b3a8f",
   "metadata": {},
   "source": [
    "## Prediction on a single data image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c6e3e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 818ms/step\n",
      "The predicted label for the new image is: Real\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Load and preprocess a single image\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img_to_array(img)  # Convert to NumPy array\n",
    "    img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Specify the path to your new image\n",
    "new_image_path = \"/Users/mac/Documents/clonerepo/Deep-Fake-Model/modi/dataset/test/real/modi4.jpg\"\n",
    "\n",
    "# Load and preprocess the new image\n",
    "new_image = load_and_preprocess_image(new_image_path)\n",
    "\n",
    "# Make predictions\n",
    "predictions = image_only_model.predict(new_image)\n",
    "\n",
    "# Assuming binary classification, you can map predictions to 'Real' or 'Fake' based on a threshold\n",
    "threshold = 0.5\n",
    "binary_predictions = (predictions > threshold).astype(int)\n",
    "class_labels = ['Real', 'Fake']\n",
    "\n",
    "mapped_prediction = class_labels[binary_predictions[0][0]]\n",
    "\n",
    "print(f'The predicted label for the new image is: {mapped_prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dec99b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"deepfake_detection_model_vgg16.h5\")\n",
    "\n",
    "#from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "#loaded_model = load_model(\"deepfake_detection_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a846e",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "The objective of this deep learning project is to develop a robust system for detecting DeepFake images, which are manipulated images generated by AI algorithms to deceive viewers. The project focuses on binary classification, distinguishing between real and manipulated images.\n",
    "\n",
    "Key Components:\n",
    "\n",
    "Dataset: A curated dataset containing a mix of real and DeepFake images is used for model training and evaluation. Each image is labeled as 'Real' or 'Fake.'\n",
    "\n",
    "Model Architecture: The project employs a convolutional neural network (CNN) architecture, specifically VGG16, known for its effectiveness in image classification tasks. Transfer learning is utilized by leveraging pre-trained weights on a large dataset.\n",
    "\n",
    "Data Preprocessing: Images are preprocessed by resizing, normalizing pixel values, and augmenting the dataset with techniques like rotation and flipping to enhance model generalization.\n",
    "\n",
    "\n",
    "Regularization Techniques: Dropout layers and batch normalization are incorporated to reduce overfitting and stabilize training.\n",
    "\n",
    "Learning Rate Scheduler: An exponential decay learning rate scheduler is implemented to dynamically adjust the learning rate during training.\n",
    "\n",
    "Evaluation Metrics: Model performance is evaluated using metrics such as accuracy, precision, recall, and F1 score. \n",
    "\n",
    "Results:\n",
    "The final model achieves a test accuracy of 95%, demonstrating its effectiveness in distinguishing between real and manipulated images. Precision and recall scores are balanced, ensuring a reliable detection system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312569bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
